{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff3a511-b801-42be-af2e-56202f6e2fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:16:21.217262Z",
     "iopub.status.busy": "2024-11-17T20:16:21.216700Z",
     "iopub.status.idle": "2024-11-17T20:16:30.927706Z",
     "shell.execute_reply": "2024-11-17T20:16:30.927081Z",
     "shell.execute_reply.started": "2024-11-17T20:16:21.217247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio==5.5.0\n",
      "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.5.0) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.5.0) (4.2.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio==5.5.0)\n",
      "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio==5.5.0)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.4.2 (from gradio==5.5.0)\n",
      "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio==5.5.0)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub>=0.25.1 (from gradio==5.5.0)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.5.0) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.5.0) (2.1.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.5.0) (1.26.3)\n",
      "Collecting orjson~=3.0 (from gradio==5.5.0)\n",
      "  Downloading orjson-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==5.5.0) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.5.0) (2.2.0)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.5.0) (9.5.0)\n",
      "Collecting pydantic>=2.0 (from gradio==5.5.0)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub (from gradio==5.5.0)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart==0.0.12 (from gradio==5.5.0)\n",
      "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/lib/python3/dist-packages (from gradio==5.5.0) (5.4.1)\n",
      "Collecting ruff>=0.2.2 (from gradio==5.5.0)\n",
      "  Downloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<1.0,>=0.1.1 (from gradio==5.5.0)\n",
      "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==5.5.0)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio==5.5.0)\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio==5.5.0)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio==5.5.0)\n",
      "  Downloading typer-0.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.5.0) (4.9.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==5.5.0)\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.4.2->gradio==5.5.0) (2023.6.0)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio==5.5.0)\n",
      "  Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5.0,>=3.0->gradio==5.5.0) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.5.0) (1.3.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx>=0.24.1->gradio==5.5.0) (2020.6.20)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio==5.5.0)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio==5.5.0)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio==5.5.0) (3.13.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio==5.5.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio==5.5.0) (4.66.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.5.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas<3.0,>=1.0->gradio==5.5.0) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.5.0) (2023.4)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio==5.5.0)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.0->gradio==5.5.0)\n",
      "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.5.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.5.0) (1.5.4)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio==5.5.0)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.5.0) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.5.0)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.5.0) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio==5.5.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio==5.5.0) (2.0.7)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.5.0)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m146.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.13.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, pydantic-core, orjson, mdurl, h11, ffmpy, annotated-types, uvicorn, starlette, pydantic, markdown-it-py, huggingface-hub, httpcore, rich, httpx, fastapi, typer, safehttpx, gradio-client, gradio\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.14\n",
      "    Uninstalling pydantic-1.10.14:\n",
      "      Successfully uninstalled pydantic-1.10.14\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.9.0\n",
      "    Uninstalling typer-0.9.0:\n",
      "      Successfully uninstalled typer-0.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.6.1 requires typer<0.10.0,>=0.3.0, but you have typer 0.13.0 which is incompatible.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.7.0 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 huggingface-hub-0.26.2 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.11 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 python-multipart-0.0.12 rich-13.9.4 ruff-0.7.4 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 typer-0.13.0 uvicorn-0.32.0 websockets-12.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio==5.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a107f9df-637b-4e92-8bcc-5b1a9263493a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:17:03.633129Z",
     "iopub.status.busy": "2024-11-17T20:17:03.632518Z",
     "iopub.status.idle": "2024-11-17T20:17:12.997212Z",
     "shell.execute_reply": "2024-11-17T20:17:12.996584Z",
     "shell.execute_reply.started": "2024-11-17T20:17:03.633109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.3)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2020.6.20)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.7/403.7 kB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m131.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: soxr, msgpack, llvmlite, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.1.0 numba-0.60.0 pooch-1.8.2 soundfile-0.12.1 soxr-0.5.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.7)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
      "  Downloading rapidfuzz-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-3.0.5 rapidfuzz-3.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa\n",
    "%pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406426a1-77ea-4633-a661-f3f83e8e7d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:59:39.095541Z",
     "iopub.status.busy": "2024-11-15T23:59:39.095071Z",
     "iopub.status.idle": "2024-11-15T23:59:46.376165Z",
     "shell.execute_reply": "2024-11-15T23:59:46.375522Z",
     "shell.execute_reply.started": "2024-11-15T23:59:39.095519Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 23:59:40.812747: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-15 23:59:40.812805: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-15 23:59:40.813816: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 23:59:40.820023: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-15 23:59:41.681917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "asr = pipeline(\"automatic-speech-recognition\", model=\"/notebooks/FTbase_model/epoch_5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139d3cb5-b0c9-4da9-ba93-9875e48a0faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:44:44.759227Z",
     "iopub.status.busy": "2024-11-15T23:44:44.757972Z",
     "iopub.status.idle": "2024-11-15T23:44:44.762906Z",
     "shell.execute_reply": "2024-11-15T23:44:44.762455Z",
     "shell.execute_reply.started": "2024-11-15T23:44:44.759191Z"
    }
   },
   "outputs": [],
   "source": [
    "def transcribe(audio):\n",
    "    print('listening')\n",
    "    text = asr(audio)['text']\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c347bf-2346-4258-9a1d-ebc813eed678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb64803-1976-4986-bffa-c66425744bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:44:53.635643Z",
     "iopub.status.busy": "2024-11-15T23:44:53.635024Z",
     "iopub.status.idle": "2024-11-15T23:44:57.153001Z",
     "shell.execute_reply": "2024-11-15T23:44:57.152299Z",
     "shell.execute_reply.started": "2024-11-15T23:44:53.635621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://5ca17e1ebdc37002e2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5ca17e1ebdc37002e2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2015, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1562, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 865, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_224/3819911708.py\", line 3, in transcribe\n",
      "    text = asr(audio)['text']\n",
      "           ^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/automatic_speech_recognition.py\", line 482, in preprocess\n",
      "    raise ValueError(f\"We expect a numpy ndarray as input, got `{type(inputs)}`\")\n",
      "ValueError: We expect a numpy ndarray as input, got `<class 'tuple'>`\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs =[gr.Audio(sources=[\"microphone\"], streaming=True)],\n",
    "    outputs = [\"text\"],\n",
    "    stream_every=0.5,\n",
    "    live=True).launch(share=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d14c969-c35b-4c7b-a40d-38e3d03913be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:59:13.132657Z",
     "iopub.status.busy": "2024-11-16T11:59:13.132310Z",
     "iopub.status.idle": "2024-11-16T11:59:23.041615Z",
     "shell.execute_reply": "2024-11-16T11:59:23.040876Z",
     "shell.execute_reply.started": "2024-11-16T11:59:13.132615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.3)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2020.6.20)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.7/403.7 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: soxr, msgpack, llvmlite, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.1.0 numba-0.60.0 pooch-1.8.2 soundfile-0.12.1 soxr-0.5.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "723342eb-0506-40e5-b3d3-cfed82e52588",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://825bb2749ba8f57971.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://825bb2749ba8f57971.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "y [-111 -102  -77 ... -543 -479 -510] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [-552 -572 -520 ...    2   16   17] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [  8   2   9 ... 595 629 630] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [ 616  635  694 ... -898 -802 -816] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [ -825  -764  -592 ... -4207 -4157 -4184] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [  -26   -11    11 ... -5651 -5567 -5449] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [   64    22   -21 ... -2466 -2389 -2175] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [   4    6    3 ...  813 1068 1135] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [-104 -113  -87 ...  -47  -32  -28] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [-104 -113  -87 ...  -47  -32  -28] sr 48000\n",
      "transcribing\n",
      "Listening...\n",
      "y [-104 -113  -87 ...  -47  -32  -28] sr 48000\n",
      "transcribing\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import librosa\n",
    "from transformers import pipeline\n",
    "\n",
    "asr = pipeline(\"automatic-speech-recognition\", model=\"/notebooks/FTbase_model/epoch_5\")\n",
    "transcriber = asr\n",
    "\n",
    "full_state=''\n",
    "# Function to process audio and transcribe\n",
    "def transcribe(stream, sound_array):\n",
    "    global full_state\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    # Gradio provides audio as a tuple (numpy array, sample rate)\n",
    "    sr, y = sound_array\n",
    "    # Ensure the audio signal is in floating-point format for processing\n",
    "    \n",
    "    print('y', y, 'sr', sr)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "    \n",
    "    # Resample audio to 16kHz if necessary\n",
    "    if sr != 16000:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        sr = 16000\n",
    "\n",
    "    if stream is not None:\n",
    "        stream = np.concatenate([stream, y])\n",
    "    else:\n",
    "        stream = y\n",
    "        \n",
    "    # Perform transcription\n",
    "    try:\n",
    "        print('transcribing')\n",
    "        transcription = transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"].replace('<unk>','')\n",
    "        \n",
    "    except Exception as e:\n",
    "        transcription = f\"Error during transcription: {e}\"\n",
    "    if full_state=='':\n",
    "        full_state = transcription\n",
    "    else:\n",
    "        full_state += ' | ' + transcription\n",
    "        \n",
    "    return stream, transcription, full_state\n",
    "\n",
    "# Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=[\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n",
    "    outputs=[\"state\", \"text\", \"text\"],\n",
    "    stream_every=2,\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "demo.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1df39ff-8b1f-4126-ba47-95bbcbdc1d22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T00:46:42.065535Z",
     "iopub.status.busy": "2024-11-16T00:46:42.065301Z",
     "iopub.status.idle": "2024-11-16T00:46:42.070669Z",
     "shell.execute_reply": "2024-11-16T00:46:42.069837Z",
     "shell.execute_reply.started": "2024-11-16T00:46:42.065518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"processor_class\": \"Wav2Vec2Processor\",\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr.feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa281396-bab6-4dec-82e9-8231bd9d04ff",
   "metadata": {},
   "source": [
    "# Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b30dc01-506e-40a3-a2b9-39416aa1c0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ed5dfdc08d4917a2c063b32391180a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0c0ee7762a495da738170591049e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41eb0eba9aa34471bc68e07cce817e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/827 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff3c6d1491e437e91a3db015ac4c5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad00f8ee75a4005943a5222efd8b96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efc9229f61b4f26946021370e518efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdb1ec9e0c54c7aa908a0ac1ee6ff46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8393a048d8419285f88b941938ba77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aefac79b98443e88bf9e6c65833c04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize ASR model\n",
    "asr = pipeline(\"automatic-speech-recognition\", model=\"tarteel-ai/whisper-base-ar-quran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d531208-bf98-42ce-8656-9cf39ac7ba76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:40:02.010085Z",
     "iopub.status.busy": "2024-11-17T20:40:02.009582Z",
     "iopub.status.idle": "2024-11-17T20:40:12.022754Z",
     "shell.execute_reply": "2024-11-17T20:40:12.022293Z",
     "shell.execute_reply.started": "2024-11-17T20:40:02.010062Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://1639f519b79918155b.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1639f519b79918155b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "asr = pipeline(\"automatic-speech-recognition\", model=\"/notebooks/FTbase_model_e5\")\n",
    "\n",
    "\n",
    "# Function to process audio and transcribe\n",
    "def transcribe(state, sound_array):\n",
    "    if sound_array is None:\n",
    "        return state, \"Listening...\"\n",
    "\n",
    "    # Extract audio array and sample rate\n",
    "    sr, y = sound_array\n",
    "    print(\"Received audio chunk:\", y.shape, \"Sample rate:\", sr)\n",
    "\n",
    "    # Ensure the audio is in floating-point format and normalized\n",
    "    if np.issubdtype(y.dtype, np.integer):\n",
    "        y = y.astype(np.float32) / np.iinfo(y.dtype).max\n",
    "\n",
    "    # Resample audio to 16kHz if necessary\n",
    "    if sr != 16000:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        sr = 16000\n",
    "\n",
    "    # Perform transcription\n",
    "    try:\n",
    "        print(\"Performing transcription...\")\n",
    "        transcription = asr({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
    "        transcription = transcription.replace(\"<unk>\", \"\").strip()\n",
    "        print(\"Transcription:\", transcription)\n",
    "    except Exception as e:\n",
    "        transcription = f\"Error during transcription: {e}\"\n",
    "\n",
    "    # Update the state\n",
    "    if state is None:\n",
    "        state = transcription\n",
    "    else:\n",
    "        state += \" \" + transcription\n",
    "\n",
    "    return state, state\n",
    "\n",
    "# Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=[\n",
    "        \"state\",\n",
    "        gr.Audio(sources=\"microphone\", streaming=True),\n",
    "    ],\n",
    "    outputs=[\n",
    "        \"state\",\n",
    "        \"text\",\n",
    "    ],\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e685d17-b437-446d-ab03-6d8de74a0a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T22:12:00.460345Z",
     "iopub.status.busy": "2024-11-17T22:12:00.459886Z",
     "iopub.status.idle": "2024-11-17T22:12:10.375509Z",
     "shell.execute_reply": "2024-11-17T22:12:10.374913Z",
     "shell.execute_reply.started": "2024-11-17T22:12:00.460325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime-gpu\n",
      "  Downloading onnxruntime_gpu-1.20.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.26.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (23.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (4.23.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Downloading onnxruntime_gpu-1.20.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (291.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.5/291.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnxruntime-gpu\n",
      "Successfully installed onnxruntime-gpu-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install onnxruntime-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a85fb9-f716-4ffb-b777-887c70be1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.transformers import optimizer\n",
    "from onnxruntime.transformers.fusion_options import FusionOptions\n",
    "\n",
    "# Example of optimization (adjust according to your model)\n",
    "optimized_model_path = \"/notebooks/notebooks/wav2vec2_model_optimized.onnx\"\n",
    "optimizer.optimize_model(\n",
    "    \"/notebooks/notebooks/wav2vec2_model.onnx\",\n",
    "    opt_level=99,  # High-level optimization\n",
    "    use_gpu=True,  # If you're using a GPU\n",
    ").save_model_to_file(optimized_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ba461-8098-4dee-80cd-0931c01171d4",
   "metadata": {},
   "source": [
    "# ONNX interference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbee5b55-9060-4dfe-af53-a26f2b6dca3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T22:08:48.294532Z",
     "iopub.status.busy": "2024-11-17T22:08:48.294036Z",
     "iopub.status.idle": "2024-11-17T22:08:51.442730Z",
     "shell.execute_reply": "2024-11-17T22:08:51.442293Z",
     "shell.execute_reply.started": "2024-11-17T22:08:48.294510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* Running on public URL: https://2f9c4af95c6c3bc635.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2f9c4af95c6c3bc635.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (72000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: مس\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: المصم\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: المصم\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: المسم\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: سم\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: اسم\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: رح\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: المسْمِ\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: يَاهَا\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: يا\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: يا\n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (24000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n",
      "Received audio chunk: (288000,) Sample rate: 48000\n",
      "Performing transcription...\n",
      "Transcription: \n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import librosa\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = \"/notebooks/notebooks/wav2vec2_model.onnx\"\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "# Load the processor for decoding (ensure this matches your model's tokenizer)\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"/notebooks/FTbase_model_e5\")\n",
    "\n",
    "# Function to process audio and transcribe using ONNX\n",
    "def transcribe(state, sound_array):\n",
    "    if sound_array is None:\n",
    "        return state, \"Listening...\"\n",
    "\n",
    "    # Extract audio array and sample rate\n",
    "    sr, y = sound_array\n",
    "    print(\"Received audio chunk:\", y.shape, \"Sample rate:\", sr)\n",
    "\n",
    "    # Ensure the audio is in floating-point format and normalized\n",
    "    if np.issubdtype(y.dtype, np.integer):\n",
    "        y = y.astype(np.float32) / np.iinfo(y.dtype).max\n",
    "\n",
    "    # Resample audio to 16kHz if necessary\n",
    "    if sr != 16000:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        sr = 16000\n",
    "\n",
    "    # ONNX expects input as a 1D array\n",
    "    input_audio = y.astype(np.float32)\n",
    "\n",
    "    # Perform transcription with ONNX\n",
    "    try:\n",
    "        print(\"Performing transcription...\")\n",
    "        # Prepare inputs for the ONNX model (add batch dimension)\n",
    "        input_audio = np.expand_dims(input_audio, axis=0).astype(np.float32)  # Shape: (1, sequence_length)\n",
    "\n",
    "        # Prepare the ONNX inputs\n",
    "        inputs = {ort_session.get_inputs()[0].name: input_audio}\n",
    "\n",
    "        # Run inference\n",
    "        outputs = ort_session.run(None, inputs)\n",
    "\n",
    "        # Decode logits to transcription\n",
    "        logits = outputs[0]  # Adjust index based on the model's output\n",
    "        predicted_ids = np.argmax(logits, axis=-1)  # Greedy decoding\n",
    "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        print(\"Transcription:\", transcription)\n",
    "    except Exception as e:\n",
    "        transcription = f\"Error during transcription: {e}\"\n",
    "\n",
    "\n",
    "    # Update the state\n",
    "    if state is None:\n",
    "        state = transcription\n",
    "    else:\n",
    "        state += \" \" + transcription\n",
    "\n",
    "    return state, state\n",
    "\n",
    "# Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=[\n",
    "        \"state\",\n",
    "        gr.Audio(sources=\"microphone\", streaming=True),\n",
    "    ],\n",
    "    outputs=[\n",
    "        \"state\",\n",
    "        \"text\",\n",
    "    ],\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5bafe7-d457-43b8-b89b-f435655c978a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T22:02:05.200096Z",
     "iopub.status.busy": "2024-11-17T22:02:05.199865Z",
     "iopub.status.idle": "2024-11-17T22:02:08.670764Z",
     "shell.execute_reply": "2024-11-17T22:02:08.670266Z",
     "shell.execute_reply.started": "2024-11-17T22:02:05.200079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.20.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.26.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (23.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (4.23.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.20.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2aaa09-af09-4da8-96b5-300be998fe68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
